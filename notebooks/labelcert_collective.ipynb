{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:09.521059100Z",
     "start_time": "2025-05-19T16:53:09.108620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def prepare():\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:09.897212900Z",
     "start_time": "2025-05-19T16:53:09.510887400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:10.409165900Z",
     "start_time": "2025-05-19T16:53:09.897212900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "prepare()\n",
    "from exp_labelcert_collective import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:10.655506500Z",
     "start_time": "2025-05-19T16:53:10.262069200Z"
    }
   },
   "outputs": [],
   "source": [
    "# example model set to GCN. For other model defintions \n",
    "# check one of the config files under config/label_certification_collective\n",
    "model_params = dict(\n",
    "    label = \"GCN\", \n",
    "    model = \"GCN\", \n",
    "    normalization = \"row_normalization\",\n",
    "    activation = \"relu\",\n",
    "    depth = 1,\n",
    "    regularizer = 0.01,\n",
    "    pred_method = \"svm\",\n",
    "    bias = False,\n",
    "    alpha_tol = 1e-4,\n",
    "    solver = \"qplayer\",\n",
    ")\n",
    "\n",
    "certificate_params = dict(\n",
    "    delta = 0.01,\n",
    "    TimeLimit = 86400,\n",
    "    LogToConsole = 1,\n",
    "    OutputFlag = 1,\n",
    "    Threads = 2,\n",
    "    Presolve = 2\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    debug_lvl = \"warning\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = \"0\",\n",
    "    dtype = torch.float64,\n",
    "    allow_tf32 = False,\n",
    "    path_gurobi_license = \"path/to/your/gurobi/license\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:11.026090900Z",
     "start_time": "2025-05-19T16:53:10.637977100Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "data_params = dict(\n",
    "    dataset = \"csbm\",\n",
    "    learning_setting = \"transductive\", \n",
    "    specification = dict(\n",
    "        classes = 2,\n",
    "        n_trn_labeled = 10,\n",
    "        n_trn_unlabeled = 0,\n",
    "        n_val = 10,\n",
    "        n_test = 180,\n",
    "        sigma = 1,\n",
    "        avg_within_class_degree = 1.58 * 2,\n",
    "        avg_between_class_degree = 0.37 * 2,\n",
    "        K = 1.5,\n",
    "        seed = 0 # used to generate the dataset & data split\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:11.622362Z",
     "start_time": "2025-05-19T16:53:11.026090900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSBM mu:\n",
      "[0.28347334 0.28347334 0.28347334 0.28347334 0.28347334 0.28347334\n",
      " 0.28347334]\n",
      "20 alphas found: ['0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100']\n",
      "Set parameter IntegralityFocus to value 1\n",
      "Set parameter IntFeasTol to value 0.0001\n",
      "Set parameter DualReductions to value 0\n",
      "Set parameter Presolve to value 2\n",
      "Set parameter Threads to value 2\n",
      "Set parameter FeasibilityTol to value 0.0001\n",
      "Set parameter OptimalityTol to value 0.0001\n",
      "Set parameter TimeLimit to value 86400\n",
      "Set parameter MIPGapAbs to value 0.99\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11+.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 4800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 2 threads\n",
      "\n",
      "Optimize a model with 2161 rows, 740 columns and 13220 nonzeros\n",
      "Model fingerprint: 0xc7d6a891\n",
      "Variable types: 480 continuous, 260 integer (240 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-04, 1e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-02, 1e+00]\n",
      "  RHS range        [1e-02, 2e+01]\n",
      "\n",
      "Loaded user MIP start with objective -0\n",
      "\n",
      "Loaded user MIP start with objective -0\n",
      "Presolve removed 2161 rows and 740 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 1 (of 16 available processors)\n",
      "\n",
      "Solution count 1: -0 \n",
      "No other solutions better than -0\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective -0.000000000000e+00, best bound -0.000000000000e+00, gap 0.0000%\n",
      "\n",
      "User-callback calls 171, time in user-callback 0.01 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'accuracy_test': 0.8666666746139526,\n 'accuracy_trn': 1.0,\n 'accuracy_cert_pois_robust': 1.0,\n 'accuracy_cert_pois_unrobust': 0,\n 'delta_absolute': 0.01,\n 'y_true_cls': [-1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'y_pred_logit': [-0.1365564065067293,\n  -0.08740311022730668,\n  -0.05948013576055779,\n  -0.07390416939135044,\n  -0.017164115263685983,\n  -0.059271368761789414,\n  -0.06886446171835346,\n  -0.021374342371872024,\n  -0.10929240139531499,\n  -0.15330986500817184,\n  -0.0788450162845486,\n  0.046217445009340066,\n  -0.12295788329362298,\n  0.021849999124536904,\n  -0.08520209910174106,\n  -0.09699014591924937,\n  -0.048882299098855775,\n  -0.1014900488819165,\n  -0.009707712537656538,\n  -0.05492542115912093,\n  -0.2231332219518651,\n  -0.09938514959496035,\n  -0.055165276343130246,\n  -0.08984576820440118,\n  -0.05507859574453635,\n  0.017839245135483024,\n  -0.12527736895023944,\n  -0.16893161556813535,\n  -0.05626213648445677,\n  -0.11692328003565022,\n  -0.10744583226717216,\n  -0.17890798632869323,\n  -0.10566675203561288,\n  -0.10373305811238794,\n  -0.03994223738466921,\n  -0.03185503052136013,\n  0.057316482327574185,\n  -0.0454931054830839,\n  -0.06543032165220428,\n  -0.12124119050227991,\n  -0.11143995424572026,\n  -0.12467805500702334,\n  -0.20074908009579046,\n  -0.11088475529510869,\n  -0.037024431136532934,\n  -0.04541444527551032,\n  -0.024507658552113225,\n  -0.04021348902027922,\n  -0.028626968821812284,\n  -0.09401888685840681,\n  -0.045833051227080736,\n  -0.28262590107734975,\n  -0.11662944542316687,\n  -0.24575248426530355,\n  -0.04898724347571853,\n  -0.05128778815312279,\n  -0.0523965594225197,\n  -0.15845202433711414,\n  -0.07298982618885216,\n  -0.030153987767093177,\n  -0.008152276914388065,\n  -0.1379187597529789,\n  -0.06542443573635917,\n  -0.03910035940168447,\n  0.006845799123760455,\n  -0.11124638560954891,\n  -0.07638737275567815,\n  -0.0258869585141468,\n  -0.10046770981151867,\n  -0.05491047643624665,\n  -0.04918479961472532,\n  -0.008848237967318378,\n  0.13399853136163586,\n  -0.06739993281000348,\n  -0.06419190648844698,\n  0.012523247978124978,\n  -0.12173571179864084,\n  -0.08036635287066092,\n  -0.1464970273205089,\n  0.12479635476975487,\n  0.013436309840221547,\n  0.12648865374379129,\n  -0.014785895568899995,\n  0.02672546901118357,\n  0.0774639261719533,\n  0.045816922660218175,\n  0.09757931684214735,\n  0.031200558430267686,\n  0.08066947698396643,\n  0.07377889708252632,\n  -0.038239106663086525,\n  0.06479726366063623,\n  -0.016170439754269732,\n  0.1063378846265538,\n  0.0261083111872364,\n  0.0718345621702294,\n  -0.00036741204088919927,\n  0.0832890915302561,\n  0.06647222917010986,\n  0.02199104071547802,\n  0.09044093716735996,\n  0.05435085481217423,\n  -0.050212194794362175,\n  0.049716695669624784,\n  0.08799831486989868,\n  0.05475111914799482,\n  -0.002739996802684804,\n  0.09116767947963267,\n  0.04439171979210745,\n  -0.020134461654569422,\n  0.089215300039728,\n  0.06492628743284462,\n  0.05348154011326356,\n  0.04990717396763062,\n  0.04259347062773507,\n  0.1326505954215524,\n  -0.02188575049899423,\n  -0.011487763472578107,\n  0.11952822463628343,\n  -0.02273697551111416,\n  0.05972411870887862,\n  0.05105529224960958,\n  0.09561030312574262,\n  0.13043794593155064,\n  0.06074892582458099,\n  0.086975562670555,\n  0.053996961690261004,\n  0.054286945189256294,\n  0.05248091598704284,\n  0.031434504346547223,\n  -0.003224402509658446,\n  0.09396622185273301,\n  0.021976945786004565,\n  0.10087401374298963,\n  0.0573332949187672,\n  0.021155077270565217,\n  0.08874848501893585,\n  0.02700086590350234,\n  0.07487732618045864,\n  -0.0021074965261554564,\n  0.10631541851914544,\n  0.060093259935098495,\n  0.0344415897369285,\n  -0.2568687111095927,\n  0.019600567822019944,\n  0.08648569746699611,\n  0.11288857995044764,\n  0.015130063001819273,\n  0.054023274456734445,\n  0.07177184072523053,\n  0.02958678565626327,\n  0.04012934041135224,\n  0.01720085869489735,\n  0.05535366340512905,\n  0.053643547191957894,\n  0.10886581983888097,\n  -0.004864254204743762,\n  0.11100809827949307,\n  -0.031097508276202415,\n  0.09094370859728118,\n  0.06173647554033098,\n  0.04066207230341229,\n  -0.023602326057382612,\n  0.05989323668743652,\n  0.07962013774399282,\n  -0.005976976283169305,\n  0.1420929892103692,\n  0.0958292870999837,\n  0.04784870354995896,\n  0.034412274263435315,\n  0.027867270381583223,\n  0.05713368616898175,\n  0.04522209745144787,\n  0.12381669826576042,\n  0.03491015378881885,\n  0.10768003086718193,\n  0.10901845421822381,\n  0.11441352019185815,\n  0.0519420726363716,\n  0.06586544698364803],\n 'y_worst_obj': [-0.13655640576911576,\n  -0.0874031097364836,\n  -0.05948013530266229,\n  -0.07390416894504719,\n  -0.017164114987183808,\n  -0.05927136831381665,\n  -0.06886446125344671,\n  -0.02137434201214652,\n  -0.10929240081970783,\n  -0.15330986423912865,\n  -0.07884501561629852,\n  0.04621744524464309,\n  -0.12295788256468566,\n  0.02184999938177157,\n  -0.08520209859855475,\n  -0.09699014519622619,\n  -0.04888229862891659,\n  -0.10149004815485729,\n  -0.009707712149223387,\n  -0.05492542043312672,\n  -0.22313322090612098,\n  -0.09938514891902037,\n  -0.05516527581164623,\n  -0.08984576762699327,\n  -0.055078595092566,\n  0.017839245423189036,\n  -0.12527736829125885,\n  -0.16893161470731846,\n  -0.05626213604231801,\n  -0.11692327941861912,\n  -0.10744583150689632,\n  -0.17890798541696598,\n  -0.10566675129021709,\n  -0.10373305741921371,\n  -0.03994223705992759,\n  -0.03185503014959531,\n  0.05731648256420194,\n  -0.04549310502521119,\n  -0.06543032114626977,\n  -0.1212411897245198,\n  -0.11143995350778081,\n  -0.12467805434035874,\n  -0.2007490791115177,\n  -0.11088475473805617,\n  -0.037024430196241645,\n  -0.04541444479460449,\n  -0.024507658165327295,\n  -0.040213488600516316,\n  -0.028626968509069865,\n  -0.0940188861663502,\n  -0.045833050839279944,\n  -0.2826258998217642,\n  -0.11662944470363015,\n  -0.2457524831961376,\n  -0.04898724309439693,\n  -0.05128778751701075,\n  -0.05239655908815679,\n  -0.15845202343222187,\n  -0.07298982581928828,\n  -0.030153987372714693,\n  -0.008152276703907897,\n  -0.13791875906044843,\n  -0.0654244353282439,\n  -0.03910035907751307,\n  0.006845799372398067,\n  -0.11124638475559855,\n  -0.07638737238089485,\n  -0.025886958216848048,\n  -0.10046770923490397,\n  -0.05491047605251442,\n  -0.049184799026119136,\n  -0.008848237623900922,\n  0.13399853162222203,\n  -0.06739993241929997,\n  -0.06419190602524927,\n  0.012523248380026167,\n  -0.1217357110611218,\n  -0.08036635238042823,\n  -0.14649702655133032,\n  0.12479635509681482,\n  0.01343631007302389,\n  0.12648865406861698,\n  -0.014785895210264983,\n  0.02672546933363264,\n  0.07746392642363492,\n  0.045816922830852126,\n  0.09757931704886166,\n  0.03120055876395497,\n  0.08066947712131627,\n  0.0737788973661521,\n  -0.03823910622188886,\n  0.06479726392161667,\n  -0.01617043945304799,\n  0.1063378848612538,\n  0.02610831142568662,\n  0.07183456233482124,\n  -0.00036741170293247416,\n  0.08328909174770624,\n  0.06647222938006732,\n  0.0219910411052303,\n  0.09044093738071816,\n  0.05435085502564503,\n  -0.05021219439152971,\n  0.04971669590299595,\n  0.08799831506810515,\n  0.054751119404446366,\n  -0.002739996476325234,\n  0.0911676796831519,\n  0.0443917202250106,\n  -0.020134461356479078,\n  0.0892153002636749,\n  0.06492628762227931,\n  0.0534815403492737,\n  0.049907174324155076,\n  0.04259347084969993,\n  0.13265059563491327,\n  -0.021885750125030596,\n  -0.011487763002911988,\n  0.11952822492843267,\n  -0.02273697501067573,\n  0.05972411901051168,\n  0.051055292453204906,\n  0.0956103033193343,\n  0.13043794616861226,\n  0.060748926076416764,\n  0.08697556287241112,\n  0.05399696204277704,\n  0.05428694548508637,\n  0.052480916255514196,\n  0.031434504561471226,\n  -0.0032244021654764497,\n  0.09396622207979527,\n  0.021976946188406062,\n  0.10087401399260543,\n  0.05733329522026823,\n  0.02115507753889874,\n  0.08874848521841025,\n  0.027000866103703274,\n  0.07487732642684192,\n  -0.0021074962745558784,\n  0.10631541869278587,\n  0.0600932602604125,\n  0.03444158993636009,\n  -0.2568687099927862,\n  0.01960056823972926,\n  0.08648569772199452,\n  0.11288858017615673,\n  0.015130063257276899,\n  0.05402327468660838,\n  0.07177184091821967,\n  0.029586785918505824,\n  0.04012934069730381,\n  0.01720085909876546,\n  0.05535366382926872,\n  0.05364354743117095,\n  0.10886582009649577,\n  -0.004864253785813698,\n  0.11100809848510236,\n  -0.03109750783750919,\n  0.0909437090150027,\n  0.06173647580579748,\n  0.04066207251952433,\n  -0.023602325598316647,\n  0.05989323695800078,\n  0.07962013795807495,\n  -0.005976976031185636,\n  0.14209298946362817,\n  0.09582928741585597,\n  0.04784870383919585,\n  0.034412274683910254,\n  0.027867270635607445,\n  0.05713368648129752,\n  0.045222097714262784,\n  0.12381669846524404,\n  0.034910154064159926,\n  0.10768003125816533,\n  0.10901845443721628,\n  0.11441352036558074,\n  0.05194207296415795,\n  0.06586544724366811],\n 'obj': -0.0,\n 'obj_bound': -0.0,\n 'y_is_robust': [1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0],\n 'y_opt_status': 2,\n 'y_flip': [-0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0],\n 'idx_train': [27, 20, 13, 80, 5, 192, 159, 128, 152, 185],\n 'idx_val': [73, 67, 55, 50, 25, 134, 196, 170, 174, 180],\n 'idx_labeled': [27,\n  20,\n  13,\n  80,\n  5,\n  192,\n  159,\n  128,\n  152,\n  185,\n  73,\n  67,\n  55,\n  50,\n  25,\n  134,\n  196,\n  170,\n  174,\n  180],\n 'idx_test': [16,\n  11,\n  10,\n  19,\n  8,\n  65,\n  9,\n  87,\n  44,\n  71,\n  42,\n  72,\n  36,\n  4,\n  53,\n  74,\n  84,\n  23,\n  39,\n  34,\n  60,\n  75,\n  83,\n  68,\n  15,\n  30,\n  2,\n  35,\n  64,\n  17,\n  66,\n  28,\n  43,\n  18,\n  52,\n  3,\n  1,\n  62,\n  24,\n  21,\n  47,\n  0,\n  6,\n  57,\n  45,\n  22,\n  26,\n  51,\n  37,\n  77,\n  49,\n  70,\n  82,\n  85,\n  40,\n  61,\n  12,\n  32,\n  86,\n  46,\n  58,\n  14,\n  38,\n  81,\n  31,\n  88,\n  48,\n  76,\n  7,\n  63,\n  69,\n  78,\n  59,\n  54,\n  29,\n  41,\n  56,\n  33,\n  79,\n  120,\n  150,\n  122,\n  169,\n  173,\n  172,\n  89,\n  182,\n  144,\n  148,\n  110,\n  145,\n  151,\n  181,\n  115,\n  161,\n  93,\n  195,\n  164,\n  147,\n  186,\n  95,\n  194,\n  143,\n  183,\n  94,\n  123,\n  163,\n  160,\n  99,\n  135,\n  102,\n  124,\n  146,\n  116,\n  188,\n  167,\n  125,\n  149,\n  193,\n  106,\n  158,\n  113,\n  154,\n  190,\n  114,\n  130,\n  168,\n  165,\n  131,\n  103,\n  108,\n  157,\n  162,\n  142,\n  184,\n  198,\n  121,\n  98,\n  117,\n  175,\n  107,\n  187,\n  111,\n  92,\n  191,\n  105,\n  136,\n  132,\n  178,\n  97,\n  153,\n  166,\n  171,\n  119,\n  176,\n  155,\n  179,\n  118,\n  133,\n  90,\n  156,\n  91,\n  101,\n  138,\n  100,\n  197,\n  137,\n  126,\n  141,\n  140,\n  104,\n  177,\n  96,\n  112,\n  129,\n  109,\n  127,\n  189,\n  139,\n  199],\n 'csbm_mu': 0.28347334265708923,\n 'csbm_p': 0.03175879396984925,\n 'csbm_q': 0.007437185929648241,\n 'data_dim': 7,\n 'min_ypred': -0.28262590107734975,\n 'max_ypred': 0.1420929892103692,\n 'min_ntklabeled': -0.6051960390713326,\n 'max_ntklabeled': 16.565788897408222,\n 'avg_ntkunlabeled': 0.7362807077476768,\n 'min_ntkunlabeled': -0.6079583647839709,\n 'max_ntkunlabeled': 9.249320453253077,\n 'cond': 345.15085935938345,\n 'cond_regularized': 295.4539346903936}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run(data_params, model_params, certificate_params, verbosity_params, other_params, seed)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:11.995327700Z",
     "start_time": "2025-05-19T16:53:11.622362Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "data_params = dict(\n",
    "    dataset = \"cba\",\n",
    "    learning_setting = \"transductive\", \n",
    "    specification = dict(\n",
    "        classes = 2,\n",
    "        n_trn_labeled = 10,\n",
    "        n_trn_unlabeled = 0,\n",
    "        n_val = 10,\n",
    "        n_test = 180,\n",
    "        sigma = 1,\n",
    "        avg_within_class_degree = 1.58 * 2,\n",
    "        avg_between_class_degree = 0.37 * 2,\n",
    "        K = 1.5,\n",
    "        m = 2,\n",
    "        seed = 0 # used to generate the dataset & data split\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:12.595257Z",
     "start_time": "2025-05-19T16:53:11.989735900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 alphas found: ['0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100', '0.0100']\n",
      "Set parameter IntegralityFocus to value 1\n",
      "Set parameter IntFeasTol to value 0.0001\n",
      "Set parameter DualReductions to value 0\n",
      "Set parameter Presolve to value 2\n",
      "Set parameter Threads to value 2\n",
      "Set parameter FeasibilityTol to value 0.0001\n",
      "Set parameter OptimalityTol to value 0.0001\n",
      "Set parameter TimeLimit to value 86400\n",
      "Set parameter MIPGapAbs to value 0.99\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11+.0 (26100.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 4800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 2 threads\n",
      "\n",
      "Optimize a model with 2161 rows, 740 columns and 13220 nonzeros\n",
      "Model fingerprint: 0xb1dc4b68\n",
      "Variable types: 480 continuous, 260 integer (240 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [7e-04, 1e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-02, 1e+00]\n",
      "  RHS range        [1e-02, 2e+01]\n",
      "Loaded user MIP start with objective -0\n",
      "\n",
      "Loaded user MIP start with objective -0\n",
      "\n",
      "Presolve removed 2161 rows and 740 columns\n",
      "Presolve time: 0.01s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 1 (of 16 available processors)\n",
      "\n",
      "Solution count 1: -0 \n",
      "No other solutions better than -0\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective -0.000000000000e+00, best bound -0.000000000000e+00, gap 0.0000%\n",
      "\n",
      "User-callback calls 171, time in user-callback 0.01 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'accuracy_test': 0.8388888835906982,\n 'accuracy_trn': 1.0,\n 'accuracy_cert_pois_robust': 1.0,\n 'accuracy_cert_pois_unrobust': 0,\n 'delta_absolute': 0.01,\n 'y_true_cls': [-1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'y_pred_logit': [-0.00376076120656041,\n  -0.036235267980364014,\n  -0.05147934477889246,\n  -0.1441464451404278,\n  -0.033320324632786884,\n  -0.11813311910606053,\n  -0.06283642502616496,\n  -0.09351520245318677,\n  -0.04556683459133497,\n  -0.012443377080348914,\n  -0.0625406402813881,\n  -0.1370127419345115,\n  -0.010959395084002083,\n  -0.10949681144782672,\n  -0.034412762520059405,\n  -0.0030242762765097624,\n  -0.0037151791024781014,\n  -0.07780955631139456,\n  -0.05519976606025419,\n  -0.016322973422575958,\n  0.014201981195298972,\n  0.0009757032555524469,\n  0.0108669096919638,\n  -0.09919238885792024,\n  -0.03939393682047039,\n  0.01697660583944893,\n  -0.08242851746902657,\n  0.04811771858026198,\n  -0.09656548781739904,\n  -0.048427550169386796,\n  -0.1094944097882167,\n  -0.009738672646648426,\n  -0.021763659247056134,\n  -0.028030394615343384,\n  -0.011353694548414284,\n  -0.03515051399597738,\n  -0.0783012641217752,\n  -0.10790739748173558,\n  0.007203583788933825,\n  -0.09917476656388435,\n  -0.12583721796985042,\n  0.006936282446258744,\n  -0.11578071955514575,\n  -0.10947176108189557,\n  -0.06903083157289708,\n  0.00022976308960497016,\n  -0.03687260031389739,\n  -0.09960176824434165,\n  -0.0928212313484468,\n  -0.06115049484710517,\n  -0.039707570923083385,\n  -0.032406045656440355,\n  0.007265843659686104,\n  0.04894787976220363,\n  -0.04847579987047598,\n  -0.04958044824075108,\n  0.02806375513992332,\n  -0.09504179720282685,\n  -0.07429371217537156,\n  -0.06123916428701366,\n  -0.08403218682546101,\n  0.0014596721558836623,\n  -0.09760000544701672,\n  -0.0332148286915398,\n  -0.06596150337455631,\n  -0.10363360056837731,\n  0.00811081683325154,\n  -0.08146791338749056,\n  -0.02420848774503395,\n  -0.04220220344950184,\n  -0.11347794549192192,\n  0.012299833333384089,\n  -0.08481088478334976,\n  -0.07701733878884513,\n  -0.07358832906387368,\n  -0.07141009165864237,\n  -0.042562936353520264,\n  -0.04468319040193802,\n  -0.08241356254120435,\n  -0.06507855542804311,\n  -0.043261033168285966,\n  -0.01483271110777431,\n  -0.047620453799805104,\n  -0.08593546554933239,\n  -0.05597301848695495,\n  -0.03872281692411163,\n  -0.12345469411110851,\n  -0.04739975885391862,\n  -0.04806526792480273,\n  -0.03847373455630608,\n  0.07154606810602718,\n  0.06004167092964734,\n  0.059593399475120275,\n  0.010884355025331983,\n  0.010484443634780237,\n  0.04922886428801671,\n  -0.03214036927303715,\n  0.06914543286047888,\n  0.038721647139397825,\n  0.0626909513341951,\n  0.055211718754353295,\n  0.09208407522541645,\n  0.05387265415278263,\n  0.09138648269303692,\n  -0.020458322211663937,\n  0.10261431773246554,\n  0.04414445400158908,\n  0.04189579120374948,\n  -0.0029218671185648444,\n  0.03966859536853838,\n  0.034041951633978974,\n  0.04285334190986201,\n  0.05726656982594473,\n  0.1102237840124012,\n  0.0696359064302036,\n  -0.06582501879058744,\n  -0.00833724703379602,\n  0.10669108436020439,\n  0.02127274231978011,\n  0.04802770175109625,\n  0.03756684852781257,\n  0.04116664405486678,\n  0.05141198180274065,\n  0.0016696788787733622,\n  0.08634615832092445,\n  0.0013701120576882862,\n  0.06773163164679813,\n  0.0642625633949275,\n  -0.00417489642232573,\n  0.021387995902711784,\n  0.0929376344193748,\n  0.015454898625554972,\n  0.06498398051766907,\n  0.08416832698824,\n  0.05275409086111457,\n  0.08466452998189779,\n  0.02762850310026887,\n  0.04847927139326465,\n  0.06460854280519521,\n  0.06077626285017321,\n  0.02991936645454439,\n  0.0628406863204384,\n  0.0403320160784259,\n  0.0475174964992353,\n  0.042835239563677116,\n  0.1136832361236403,\n  -0.01399268161499797,\n  0.0724648105478059,\n  0.07282673402440812,\n  0.013507309695260237,\n  0.012692407032703697,\n  0.0017993374245955651,\n  0.09134533060074813,\n  -0.0930640001089344,\n  -0.002512560732837746,\n  0.05956059641876566,\n  0.009570428325079698,\n  0.08698692117329195,\n  -0.015632022627950944,\n  0.04581263314252507,\n  -0.02088472326692356,\n  0.05978250674549293,\n  0.07477959273683894,\n  0.058097033160299794,\n  0.0876277070960545,\n  0.058163640938995426,\n  0.05914965770823343,\n  -0.0203614896421257,\n  0.09962414410651477,\n  0.04614986533578848,\n  -0.03342002734260806,\n  0.04003344974496896,\n  0.014160436761258981,\n  0.009070550877813617,\n  0.031549618515334305,\n  0.1241292855765363,\n  0.03568354332989426,\n  0.022189296490205096,\n  0.015811212483327806,\n  -0.011695006259716922],\n 'y_worst_obj': [-0.003760767062106124,\n  -0.03623527350906873,\n  -0.051479350348789185,\n  -0.14414645197026626,\n  -0.0333203308493657,\n  -0.11813312537214118,\n  -0.0628364303938489,\n  -0.09351520817244324,\n  -0.045566840120544044,\n  -0.012443384206997445,\n  -0.06254064617045832,\n  -0.13701274871181515,\n  -0.010959399040630036,\n  -0.1094968190101406,\n  -0.03441276714727699,\n  -0.00302428254149981,\n  -0.003715183735672735,\n  -0.07780956292186716,\n  -0.05519977175846649,\n  -0.01632297812287951,\n  0.014201975617172895,\n  0.0009756978962612989,\n  0.010866904212084982,\n  -0.09919239526423264,\n  -0.0393939419494872,\n  0.01697660095848612,\n  -0.0824285244534791,\n  0.048117711168450164,\n  -0.09656549356799146,\n  -0.048427557959664316,\n  -0.10949441813511634,\n  -0.009738678363053851,\n  -0.021763664368950473,\n  -0.028030399148507818,\n  -0.011353701509769887,\n  -0.03515051835969852,\n  -0.07830127108695706,\n  -0.1079074049044386,\n  0.007203577477370927,\n  -0.09917477293446378,\n  -0.12583722504660677,\n  0.00693627716391268,\n  -0.11578072847434413,\n  -0.10947176718832322,\n  -0.06903083685095886,\n  0.0002297574266293366,\n  -0.03687260612167864,\n  -0.09960177381336076,\n  -0.09282123970800023,\n  -0.061150502196961526,\n  -0.03970757965360623,\n  -0.03240605106832542,\n  0.007265833835574782,\n  0.048947873328188916,\n  -0.04847580519446165,\n  -0.04958045276088163,\n  0.02806374842946171,\n  -0.0950418021717624,\n  -0.07429371807390603,\n  -0.06123916978300867,\n  -0.08403219270125727,\n  0.0014596681953327785,\n  -0.09760001175145201,\n  -0.03321483402041344,\n  -0.06596151046111448,\n  -0.10363360758371128,\n  0.008110812580971235,\n  -0.08146792034006767,\n  -0.02420849346147704,\n  -0.0422022073772058,\n  -0.11347795116766975,\n  0.01229982817385653,\n  -0.08481089015001635,\n  -0.07701734509535388,\n  -0.07358833544953387,\n  -0.07141009616320174,\n  -0.04256294142191267,\n  -0.04468319636055809,\n  -0.08241356787072532,\n  -0.06507856020740024,\n  -0.04326103840251283,\n  -0.014832719051683173,\n  -0.047620457557906,\n  -0.0859354715177257,\n  -0.05597302572391051,\n  -0.03872282196302916,\n  -0.12345470057432006,\n  -0.04739976411976938,\n  -0.048065272632873524,\n  -0.03847374090138953,\n  0.07154605888436619,\n  0.060041663026710254,\n  0.0595933923408727,\n  0.010884350494451044,\n  0.01048443863347311,\n  0.04922885655614311,\n  -0.03214037485019698,\n  0.06914542502266678,\n  0.03872164066144271,\n  0.06269094526721858,\n  0.055211711763756305,\n  0.09208406567646679,\n  0.053872648786474894,\n  0.09138647321008672,\n  -0.02045833008431059,\n  0.10261430631959204,\n  0.04414444770865602,\n  0.04189578645261366,\n  -0.0029218728382941067,\n  0.0396685892595349,\n  0.03404194456122607,\n  0.042853336636124395,\n  0.0572665621602511,\n  0.11022377371939704,\n  0.0696358992326689,\n  -0.06582502388726903,\n  -0.008337252521936553,\n  0.10669107575189585,\n  0.021272736239059856,\n  0.04802769255916059,\n  0.03756684140126984,\n  0.04116663841045539,\n  0.051411974728828316,\n  0.001669675113610044,\n  0.08634614896449685,\n  0.001370107679734705,\n  0.06773162535043933,\n  0.0642625575937546,\n  -0.004174902994644611,\n  0.021387989302024235,\n  0.09293762657680682,\n  0.015454891869323376,\n  0.06498397371040063,\n  0.08416831739606495,\n  0.05275408465885031,\n  0.08466452016399155,\n  0.027628497232828043,\n  0.048479263494822025,\n  0.06460853470742564,\n  0.06077625539103226,\n  0.029919361316503,\n  0.0628406778596609,\n  0.04033201055392471,\n  0.04751749075859648,\n  0.042835233990515045,\n  0.11368322708644837,\n  -0.013992686379972231,\n  0.07246479935024638,\n  0.07282672578195488,\n  0.0135073039233575,\n  0.012692402799353474,\n  0.0017993327804462396,\n  0.09134532286629116,\n  -0.0930640080868122,\n  -0.0025125666331758424,\n  0.059560589193164766,\n  0.00957042214721171,\n  0.08698691283364135,\n  -0.0156320278481435,\n  0.045812625926459016,\n  -0.020884727523063484,\n  0.05978249868186484,\n  0.07477958544176305,\n  0.058097025658619385,\n  0.08762769800183882,\n  0.05816363351434026,\n  0.05914964961819272,\n  -0.020361495337221758,\n  0.09962413505427356,\n  0.04614985987518877,\n  -0.03342003384654743,\n  0.04003344494919609,\n  0.014160431567928148,\n  0.009070545411758934,\n  0.03154961252078413,\n  0.12412927309332844,\n  0.03568353506600208,\n  0.02218928781594046,\n  0.015811202986979116,\n  -0.011695010997590845],\n 'obj': -0.0,\n 'obj_bound': -0.0,\n 'y_is_robust': [1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0],\n 'y_opt_status': 2,\n 'y_flip': [-0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  -0.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0,\n  1.0],\n 'idx_train': [81, 36, 20, 5, 92, 158, 119, 153, 189, 159],\n 'idx_val': [16, 93, 52, 71, 68, 120, 180, 198, 157, 161],\n 'idx_labeled': [81,\n  36,\n  20,\n  5,\n  92,\n  158,\n  119,\n  153,\n  189,\n  159,\n  16,\n  93,\n  52,\n  71,\n  68,\n  120,\n  180,\n  198,\n  157,\n  161],\n 'idx_test': [82,\n  13,\n  80,\n  37,\n  11,\n  10,\n  74,\n  8,\n  27,\n  9,\n  96,\n  23,\n  64,\n  19,\n  50,\n  90,\n  84,\n  44,\n  70,\n  4,\n  25,\n  89,\n  34,\n  39,\n  62,\n  57,\n  72,\n  42,\n  65,\n  15,\n  30,\n  2,\n  35,\n  86,\n  43,\n  17,\n  97,\n  28,\n  75,\n  18,\n  60,\n  3,\n  1,\n  55,\n  53,\n  24,\n  67,\n  21,\n  47,\n  0,\n  6,\n  66,\n  45,\n  22,\n  83,\n  26,\n  51,\n  49,\n  85,\n  91,\n  94,\n  40,\n  61,\n  12,\n  32,\n  98,\n  46,\n  58,\n  14,\n  73,\n  38,\n  87,\n  31,\n  88,\n  48,\n  77,\n  76,\n  7,\n  63,\n  69,\n  78,\n  59,\n  54,\n  29,\n  41,\n  56,\n  33,\n  79,\n  95,\n  168,\n  188,\n  103,\n  194,\n  99,\n  132,\n  125,\n  178,\n  179,\n  144,\n  171,\n  104,\n  133,\n  197,\n  162,\n  138,\n  105,\n  145,\n  139,\n  160,\n  173,\n  167,\n  109,\n  134,\n  112,\n  137,\n  126,\n  174,\n  156,\n  191,\n  199,\n  116,\n  186,\n  123,\n  155,\n  196,\n  124,\n  140,\n  175,\n  172,\n  141,\n  113,\n  118,\n  164,\n  169,\n  152,\n  190,\n  135,\n  149,\n  177,\n  154,\n  130,\n  192,\n  170,\n  131,\n  108,\n  127,\n  181,\n  117,\n  193,\n  121,\n  102,\n  183,\n  115,\n  146,\n  142,\n  184,\n  107,\n  163,\n  176,\n  129,\n  182,\n  165,\n  185,\n  128,\n  143,\n  100,\n  166,\n  101,\n  111,\n  148,\n  110,\n  195,\n  147,\n  136,\n  151,\n  150,\n  114,\n  187,\n  106,\n  122],\n 'data_dim': 7,\n 'min_ypred': -0.1441464451404278,\n 'max_ypred': 0.1241292855765363,\n 'min_ntklabeled': -0.15527623399937046,\n 'max_ntklabeled': 2.9609016390645726,\n 'avg_ntkunlabeled': 0.625814702754208,\n 'min_ntkunlabeled': -0.22999592683887787,\n 'max_ntkunlabeled': 3.4997062765934235,\n 'cond': 341.36275728705294,\n 'cond_regularized': 272.94488997803103}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run(data_params, model_params, certificate_params, verbosity_params, other_params, seed)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:12.941416Z",
     "start_time": "2025-05-19T16:53:12.582689700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_params = dict(\n",
    "    dataset = \"cora_ml_binary\", # use \"citeseer_binary\" for citeseer\n",
    "    learning_setting = \"transductive\", \n",
    "    specification = dict(\n",
    "        n_per_class = 10,\n",
    "        fraction_test = 0.01,\n",
    "        data_dir = \"./data\",\n",
    "        make_undirected = True,\n",
    "        balance_test = True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T16:53:13.598089400Z",
     "start_time": "2025-05-19T16:53:12.934256800Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\cora_ml.npz'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m result = \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcertificate_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbosity_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\TU Delft\\000 MASTERS\\Q4\\Scalable ML Research\\qpcert\\venv\\Lib\\site-packages\\sacred\\config\\captured_function.py:42\u001B[39m, in \u001B[36mcaptured_function\u001B[39m\u001B[34m(wrapped, instance, args, kwargs)\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;66;03m# =================== run actual function =================================\u001B[39;00m\n\u001B[32m     41\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ConfigError.track(wrapped.config, wrapped.prefix):\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m     result = \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[38;5;66;03m# =========================================================================\u001B[39;00m\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m wrapped.logger \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\TU Delft\\000 MASTERS\\Q4\\Scalable ML Research\\qpcert\\exp_labelcert_collective.py:209\u001B[39m, in \u001B[36mrun\u001B[39m\u001B[34m(data_params, model_params, certificate_params, verbosity_params, other_params, seed, _run)\u001B[39m\n\u001B[32m    197\u001B[39m \u001B[38;5;129m@ex\u001B[39m.automain\n\u001B[32m    198\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun\u001B[39m(data_params: Dict[\u001B[38;5;28mstr\u001B[39m, Any], \n\u001B[32m    199\u001B[39m         model_params: Dict[\u001B[38;5;28mstr\u001B[39m, Any], \n\u001B[32m   (...)\u001B[39m\u001B[32m    203\u001B[39m         seed: \u001B[38;5;28mint\u001B[39m, \n\u001B[32m    204\u001B[39m         _run: Run):\n\u001B[32m    205\u001B[39m     device, dtype, rng = setup_experiment(data_params, model_params, \n\u001B[32m    206\u001B[39m                                           certificate_params, verbosity_params, \n\u001B[32m    207\u001B[39m                                           other_params, seed)\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m     X, A, y, mu, p, q = \u001B[43mget_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    210\u001B[39m     n_edges = np.sum(A) / \u001B[32m2\u001B[39m\n\u001B[32m    211\u001B[39m     logging.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mSampled \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_edges\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.0f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m edges.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\TU Delft\\000 MASTERS\\Q4\\Scalable ML Research\\qpcert\\src\\data.py:343\u001B[39m, in \u001B[36mget_graph\u001B[39m\u001B[34m(data_params, sort, return_csbm)\u001B[39m\n\u001B[32m    341\u001B[39m     X, A, y = get_cora_ml(data_params[\u001B[33m\"\u001B[39m\u001B[33mspecification\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    342\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m data_params[\u001B[33m\"\u001B[39m\u001B[33mdataset\u001B[39m\u001B[33m\"\u001B[39m] == \u001B[33m\"\u001B[39m\u001B[33mcora_ml_binary\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m343\u001B[39m     X, A, y = \u001B[43mget_cora_ml_binary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_params\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mspecification\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    344\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m data_params[\u001B[33m\"\u001B[39m\u001B[33mdataset\u001B[39m\u001B[33m\"\u001B[39m] == \u001B[33m\"\u001B[39m\u001B[33mcora_ml_cont_binary\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    345\u001B[39m     X, A, y = get_cora_ml_cont_binary(data_params[\u001B[33m\"\u001B[39m\u001B[33mspecification\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\TU Delft\\000 MASTERS\\Q4\\Scalable ML Research\\qpcert\\src\\data.py:292\u001B[39m, in \u001B[36mget_cora_ml_binary\u001B[39m\u001B[34m(specification)\u001B[39m\n\u001B[32m    291\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_cora_ml_binary\u001B[39m(specification: Dict[\u001B[38;5;28mstr\u001B[39m, Any]):\n\u001B[32m--> \u001B[39m\u001B[32m292\u001B[39m     X, A, y = \u001B[43mget_cora_ml\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspecification\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _make_binary(X, A, y)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\TU Delft\\000 MASTERS\\Q4\\Scalable ML Research\\qpcert\\src\\data.py:142\u001B[39m, in \u001B[36mget_cora_ml\u001B[39m\u001B[34m(specification)\u001B[39m\n\u001B[32m    140\u001B[39m     directory = Path(directory)\n\u001B[32m    141\u001B[39m path_to_file = directory / (\u001B[33m\"\u001B[39m\u001B[33mcora_ml.npz\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m142\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_to_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m loader:\n\u001B[32m    143\u001B[39m     loader = \u001B[38;5;28mdict\u001B[39m(loader)\n\u001B[32m    144\u001B[39m     adj_matrix = sp.csr_matrix((loader[\u001B[33m'\u001B[39m\u001B[33madj_matrix.data\u001B[39m\u001B[33m'\u001B[39m], \n\u001B[32m    145\u001B[39m                                 loader[\u001B[33m'\u001B[39m\u001B[33madj_matrix.indices\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m    146\u001B[39m                                 loader[\u001B[33m'\u001B[39m\u001B[33madj_matrix.indptr\u001B[39m\u001B[33m'\u001B[39m]), \n\u001B[32m    147\u001B[39m                                 shape=loader[\u001B[33m'\u001B[39m\u001B[33madj_matrix.shape\u001B[39m\u001B[33m'\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\TU Delft\\000 MASTERS\\Q4\\Scalable ML Research\\qpcert\\venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[39m\n\u001B[32m    425\u001B[39m     own_fid = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    426\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m427\u001B[39m     fid = stack.enter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[32m    428\u001B[39m     own_fid = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    430\u001B[39m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'data\\\\cora_ml.npz'"
     ]
    }
   ],
   "source": [
    "result = run(data_params, model_params, certificate_params, verbosity_params, other_params, seed)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_ntk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
